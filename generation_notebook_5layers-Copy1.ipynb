{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertLMHeadModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertLMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertLMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertLMHeadModel were not initialized from the model checkpoint at emilyalsentzer/Bio_ClinicalBERT and are newly initialized: ['bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from dataloader import *\n",
    "from utils import *\n",
    "from model_vit_bert3 import ViTConfigCustom, ViTModelCustom, CustomVEDConfig, CustomVisionEncoderDecoder\n",
    "from training_script_vit_bert_3layers_bsgt1_v2 import LightningModel\n",
    "\n",
    "# models: Encoder    \n",
    "encoder = ViTModelCustom(config=ViTConfigCustom(hidden_size=576), pretrain_4k='vit4k_xs_dino', freeze_4k=True)\n",
    "\n",
    "# decoder\n",
    "decoder_model_name=\"emilyalsentzer/Bio_ClinicalBERT\"\n",
    "decoder = AutoModelForCausalLM.from_pretrained(decoder_model_name, is_decoder=True, add_cross_attention=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(decoder_model_name)\n",
    "\n",
    "# encoder decoder model\n",
    "model=CustomVisionEncoderDecoder(config=CustomVEDConfig(),encoder=encoder, decoder=decoder)\n",
    "model.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "lightning_model = LightningModel(model, tokenizer, model_lr=1e-2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "ckpt=\"/scratch/ss4yd/logs_only_vit_bert_fullexpv2_freezeFalse/my_model/version_23/checkpoints/epoch=5-val_loss=0.93-step=4254.00.ckpt\"\n",
    "lightning_model.load_state_dict(torch.load(ckpt,map_location=device)['state_dict'])\n",
    "lightning_model.eval()\n",
    "\n",
    "len(list(*decoder.bert.encoder.children())[:-5])\n",
    "\n",
    "model=lightning_model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      834\n",
       "female    422\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_path='/home/ss4yd/nlp/full_experiments/data_files/all_gtex_data.pickle'\n",
    "df=pd.read_pickle(df_path)\n",
    "\n",
    "# df=df[df.dtype=='train']\n",
    "# print(df.sex.value_counts())\n",
    "\n",
    "df=df[df.dtype=='test']\n",
    "df.sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6473577235772358, 28996)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "637/(637+347), tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>svs_path</th>\n",
       "      <th>patch_path</th>\n",
       "      <th>reps_path</th>\n",
       "      <th>tissue_type</th>\n",
       "      <th>notes</th>\n",
       "      <th>new_notes</th>\n",
       "      <th>sex</th>\n",
       "      <th>dtype</th>\n",
       "      <th>reps4kpath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23864</th>\n",
       "      <td>GTEX-14DAQ-1126</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-14DAQ-1126.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Heart - Left Ventricle</td>\n",
       "      <td>2 pieces, minimal interstitial fibrosis, chron...</td>\n",
       "      <td>this is a heart - left ventricle tissue from a...</td>\n",
       "      <td>female</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23865</th>\n",
       "      <td>GTEX-183WM-0926</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-183WM-0926.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Heart - Atrial Appendage</td>\n",
       "      <td>2 pieces, no abnormalities</td>\n",
       "      <td>this is a heart - atrial appendage tissue from...</td>\n",
       "      <td>female</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23866</th>\n",
       "      <td>GTEX-15ER7-1626</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-15ER7-1626.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Breast - Mammary Tissue</td>\n",
       "      <td>2 pieces; 50 and 70% fat with fibrocollagenous...</td>\n",
       "      <td>this is a breast - mammary tissue tissue from ...</td>\n",
       "      <td>female</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23867</th>\n",
       "      <td>GTEX-1AX8Z-0126</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-1AX8Z-0126.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Skin - Sun Exposed (Lower leg)</td>\n",
       "      <td>6 pieces; 20% dermal fat; well trimmed</td>\n",
       "      <td>this is a skin - sun exposed (lower leg) tissu...</td>\n",
       "      <td>male</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23868</th>\n",
       "      <td>GTEX-1HSKV-2426</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-1HSKV-2426.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Esophagus - Mucosa</td>\n",
       "      <td>6 pieces; includes few clusters of submucosal ...</td>\n",
       "      <td>this is a esophagus - mucosa tissue from a mal...</td>\n",
       "      <td>male</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25115</th>\n",
       "      <td>GTEX-Y5V5-2726</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-Y5V5-2726.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Artery - Tibial</td>\n",
       "      <td>2 pieces, 3x2.5 &amp; 4x3mm; one aliquot has ~0.5m...</td>\n",
       "      <td>this is a artery - tibial tissue from a female...</td>\n",
       "      <td>female</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25116</th>\n",
       "      <td>GTEX-1OJC4-0126</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-1OJC4-0126.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Skin - Sun Exposed (Lower leg)</td>\n",
       "      <td>6 pieces; relatively well trimmed, include up ...</td>\n",
       "      <td>this is a skin - sun exposed (lower leg) tissu...</td>\n",
       "      <td>female</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25117</th>\n",
       "      <td>GTEX-1I1GT-1426</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-1I1GT-1426.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Esophagus - Mucosa</td>\n",
       "      <td>6 pieces</td>\n",
       "      <td>this is a esophagus - mucosa tissue from a fem...</td>\n",
       "      <td>female</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25118</th>\n",
       "      <td>GTEX-1RAZR-1426</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-1RAZR-1426.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Esophagus - Gastroesophageal Junction</td>\n",
       "      <td>5 pieces; 2 have 10 &amp; 20% stromal contents</td>\n",
       "      <td>this is a esophagus - gastroesophageal junctio...</td>\n",
       "      <td>male</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25119</th>\n",
       "      <td>GTEX-11ZVC-0226</td>\n",
       "      <td>/scratch/ss4yd/gtex_data_new/GTEX-11ZVC-0226.svs</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/pa...</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gtex_data/hi...</td>\n",
       "      <td>Lung</td>\n",
       "      <td>2 pieces; fibrosis. vascular sclerosis; pleura...</td>\n",
       "      <td>this is a lung tissue from a female patient an...</td>\n",
       "      <td>female</td>\n",
       "      <td>test</td>\n",
       "      <td>/project/GutIntelligenceLab/ss4yd/gdc_data/hip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pid                                          svs_path  \\\n",
       "23864  GTEX-14DAQ-1126  /scratch/ss4yd/gtex_data_new/GTEX-14DAQ-1126.svs   \n",
       "23865  GTEX-183WM-0926  /scratch/ss4yd/gtex_data_new/GTEX-183WM-0926.svs   \n",
       "23866  GTEX-15ER7-1626  /scratch/ss4yd/gtex_data_new/GTEX-15ER7-1626.svs   \n",
       "23867  GTEX-1AX8Z-0126  /scratch/ss4yd/gtex_data_new/GTEX-1AX8Z-0126.svs   \n",
       "23868  GTEX-1HSKV-2426  /scratch/ss4yd/gtex_data_new/GTEX-1HSKV-2426.svs   \n",
       "...                ...                                               ...   \n",
       "25115   GTEX-Y5V5-2726   /scratch/ss4yd/gtex_data_new/GTEX-Y5V5-2726.svs   \n",
       "25116  GTEX-1OJC4-0126  /scratch/ss4yd/gtex_data_new/GTEX-1OJC4-0126.svs   \n",
       "25117  GTEX-1I1GT-1426  /scratch/ss4yd/gtex_data_new/GTEX-1I1GT-1426.svs   \n",
       "25118  GTEX-1RAZR-1426  /scratch/ss4yd/gtex_data_new/GTEX-1RAZR-1426.svs   \n",
       "25119  GTEX-11ZVC-0226  /scratch/ss4yd/gtex_data_new/GTEX-11ZVC-0226.svs   \n",
       "\n",
       "                                              patch_path  \\\n",
       "23864  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "23865  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "23866  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "23867  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "23868  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "...                                                  ...   \n",
       "25115  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "25116  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "25117  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "25118  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "25119  /project/GutIntelligenceLab/ss4yd/gtex_data/pa...   \n",
       "\n",
       "                                               reps_path  \\\n",
       "23864  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "23865  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "23866  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "23867  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "23868  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "...                                                  ...   \n",
       "25115  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "25116  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "25117  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "25118  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "25119  /project/GutIntelligenceLab/ss4yd/gtex_data/hi...   \n",
       "\n",
       "                                 tissue_type  \\\n",
       "23864                 Heart - Left Ventricle   \n",
       "23865               Heart - Atrial Appendage   \n",
       "23866                Breast - Mammary Tissue   \n",
       "23867         Skin - Sun Exposed (Lower leg)   \n",
       "23868                     Esophagus - Mucosa   \n",
       "...                                      ...   \n",
       "25115                        Artery - Tibial   \n",
       "25116         Skin - Sun Exposed (Lower leg)   \n",
       "25117                     Esophagus - Mucosa   \n",
       "25118  Esophagus - Gastroesophageal Junction   \n",
       "25119                                   Lung   \n",
       "\n",
       "                                                   notes  \\\n",
       "23864  2 pieces, minimal interstitial fibrosis, chron...   \n",
       "23865                         2 pieces, no abnormalities   \n",
       "23866  2 pieces; 50 and 70% fat with fibrocollagenous...   \n",
       "23867             6 pieces; 20% dermal fat; well trimmed   \n",
       "23868  6 pieces; includes few clusters of submucosal ...   \n",
       "...                                                  ...   \n",
       "25115  2 pieces, 3x2.5 & 4x3mm; one aliquot has ~0.5m...   \n",
       "25116  6 pieces; relatively well trimmed, include up ...   \n",
       "25117                                           6 pieces   \n",
       "25118         5 pieces; 2 have 10 & 20% stromal contents   \n",
       "25119  2 pieces; fibrosis. vascular sclerosis; pleura...   \n",
       "\n",
       "                                               new_notes     sex dtype  \\\n",
       "23864  this is a heart - left ventricle tissue from a...  female  test   \n",
       "23865  this is a heart - atrial appendage tissue from...  female  test   \n",
       "23866  this is a breast - mammary tissue tissue from ...  female  test   \n",
       "23867  this is a skin - sun exposed (lower leg) tissu...    male  test   \n",
       "23868  this is a esophagus - mucosa tissue from a mal...    male  test   \n",
       "...                                                  ...     ...   ...   \n",
       "25115  this is a artery - tibial tissue from a female...  female  test   \n",
       "25116  this is a skin - sun exposed (lower leg) tissu...  female  test   \n",
       "25117  this is a esophagus - mucosa tissue from a fem...  female  test   \n",
       "25118  this is a esophagus - gastroesophageal junctio...    male  test   \n",
       "25119  this is a lung tissue from a female patient an...  female  test   \n",
       "\n",
       "                                              reps4kpath  \n",
       "23864  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "23865  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "23866  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "23867  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "23868  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "...                                                  ...  \n",
       "25115  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "25116  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "25117  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "25118  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "25119  /project/GutIntelligenceLab/ss4yd/gdc_data/hip...  \n",
       "\n",
       "[1256 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reps_path=df['reps_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-1RAZR-1426\n",
      "Actual Note: \n",
      " this is a esophagus - gastroesophageal junction tissue from a male patient and it has 5 pieces; 2 have 10 & 20% stromal contents\n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import *\n",
    "df_path='/home/ss4yd/nlp/full_experiments/data_files/all_gtex_data.pickle'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size=32\n",
    "epochs=30\n",
    "model_lr=2e-5\n",
    "\n",
    "n_layers=3\n",
    "\n",
    "num_workers=1\n",
    "test_loader = torch.utils.data.DataLoader(ResnetPlusVitDatasetV3(df_path,text_decode_model=decoder_model_name, dtype='test'), \n",
    "                                              batch_size=1, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    pixel_values, labels, attention_mask, encoder_attention_mask = batch\n",
    "    break\n",
    "# model._prepare_encoder_decoder_kwargs_for_generation(pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "outs=model(pixel_values=pixel_values, \n",
    "           attention_mask=encoder_attention_mask,\n",
    "           labels=labels, \n",
    "           decoder_attention_mask=attention_mask,\n",
    "           output_attentions=True\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['loss', 'logits', 'past_key_values', 'decoder_attentions', 'cross_attentions', 'encoder_last_hidden_state'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outs['cross_attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n",
      "torch.Size([1, 12, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(outs['cross_attentions'])):\n",
    "    print(outs['cross_attentions'][i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-1HR9M-0626\n",
      "Actual Note: \n",
      " this is a thyroid tissue from a male patient and it has 2 pieces; 10% internal fat content\n",
      "Generated Note: \n",
      " this is a thyroid tissue from a male patient and it has 2 pieces ; 1 piece has 50 % fat \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=1, do_sample=False, \n",
    "                                      return_dict_in_generate=True, output_attentions=True)\n",
    "decoded_cap=tokenizer.decode(gencap['sequences'][0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 576])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[CLS] this is a thyroid tissue from a male patient and it has 2 pieces ; 1 piece has 50 % fat [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]. this is a thyroid tissue ( omentum ) ; other has 2 pieces ; other has 2 pieces [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP] [SEP]',\n",
       " torch.Size([1, 28, 576]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  1142,  1110,   170, 21153, 16219,  7918,  1121,   170,  2581,\n",
       "          5351,  1105,  1122,  1144,   123,  3423,   132,   122,  2727,  1144,\n",
       "          1851,   110,  7930,   102,   102,   102,   102,   102,   102,   102,\n",
       "           102,   102,   102,   102,   102,   102,   102,   102,   102,   102,\n",
       "           102,   102,   102,   102,   102,   102,   102,   102,   102,   102,\n",
       "           102,   102,   102,   102,   102,   102,   102,   102,   102,   102,\n",
       "           102,   102,   102,   102,   102,   102,   119,  1142,  1110,   170,\n",
       "         21153, 16219,  7918,   113,   184,  1880,  1818,   114,   132,  1168,\n",
       "          1144,   123,  3423,   132,  1168,  1144,   123,  3423,   102,   102,\n",
       "           102,   102,   102,   102,   102,   102,   102,   102,   102,   102,\n",
       "           102,   102,   102,   102,   102,   102,   102,   102,   102,   102,\n",
       "           102,   102,   102,   102,   102,   102,   102,   102,   102,   102,\n",
       "           102,   102,   102,   102,   102,   102,   102,   102]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gencap['sequences']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['sequences', 'decoder_attentions', 'cross_attentions'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gencap.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gencap['cross_attentions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n"
     ]
    }
   ],
   "source": [
    "index=0\n",
    "print(len(gencap['cross_attentions'][index]))\n",
    "for i in range(len(gencap['cross_attentions'][index])):\n",
    "    print(gencap['cross_attentions'][index][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n",
      "torch.Size([1, 12, 1, 28])\n"
     ]
    }
   ],
   "source": [
    "index=-1\n",
    "for i in range(len(gencap['cross_attentions'][index])):\n",
    "    print(gencap['cross_attentions'][index][i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gencap['cross_attentions'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-QDT8-2826\n",
      "Actual Note: \n",
      " this is a bladder tissue from a female patient and it has 6   ~8x5mm pieces.  urotherlium nearly completely sloughed; muscularis/adipose tissue is >99% of sections\n",
      "Generated Note: \n",
      " this is a esophagus - gastroesophageal junction tissue from a male patient and it has 6 pieces, all muscularis, good specimens \n"
     ]
    }
   ],
   "source": [
    "# samp = df.sample(1)\n",
    "samp = df[df.pid=='GTEX-QDT8-2826']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-139UC-0426\n",
      "Actual Note: \n",
      " this is a heart - left ventricle tissue from a male patient and it has 2 pieces, moderate interstitial fibrosis with ~3mm remote infarct, delineated\n",
      "Generated Note: \n",
      " this is a heart - left ventricle tissue from a male patient and it has 2 pieces ; interstitial fibrosis \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-1L5NE-0426\n",
      "Actual Note: \n",
      " this is a heart - left ventricle tissue from a male patient and it has 2 pieces, moderate chronic ischemic changes/interstitial fibrosis; ~2mm remote micro-infarct encircled.\n",
      "Generated Note: \n",
      " this is a heart - left ventricle tissue from a male patient and it has 2 pieces, moderate interstitial fibrosis / chronic ischemic changes \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-1H11D-0926\n",
      "Actual Note: \n",
      " this is a pancreas tissue from a male patient and it has 2 pieces; both include up to 20% attached fat, focal squamous metaplasia of duct\n",
      "Generated Note: \n",
      " this is a pancreas tissue from a male patient and it has 2 pieces, advanced saponification ; islets not well visualized ; \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-V955-2626\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces ~8x6mm.  20% occlusive atherosclerosis, relatively clean specimens\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces, 3x2 & 3x2mm ; medial calcification ; atheromatous plaques ; ~ 50 % of aliquot \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-ZTPG-2326\n",
      "Actual Note: \n",
      " this is a adipose - visceral (omentum) tissue from a female patient and it has 2 pieces\n",
      "Generated Note: \n",
      " this is a adipose - visceral ( omentum ) tissue from a male patient and it has 2 pieces ; large vessels, no vascular tissue \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-1GZ2Q-1526\n",
      "Actual Note: \n",
      " this is a kidney - cortex tissue from a male patient and it has 6 pieces; renal cortex with patchy interstitial fibrosis and  hyalinized glomeruli (rep arrowed)\n",
      "Generated Note: \n",
      " this is a kidney - cortex tissue from a male patient and it has 6 pieces ; glomeruli in all sections, arteriolar sclerosis ; tubules severely autolyzed ; glomeruli in medulla \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-ZV6S-1826\n",
      "Actual Note: \n",
      " this is a breast - mammary tissue tissue from a female patient and it has 2 pieces, ~70% loose fibrous tissue, epithelium is <5%, small floater  (colonic gland) delineated\n",
      "Generated Note: \n",
      " this is a breast - mammary tissue tissue from a male patient and it has 2 pieces ; fibroadipose tissue with gynecomastoid stroma and ductal structures \n"
     ]
    }
   ],
   "source": [
    "samp = df.sample(1)\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effect of BEAM Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces ; no plaques ; well trimmed ; no plaques ; no plaques \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=1, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces ; well trimmed ; no plaques ; no plaques ; no plaques \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=2, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces ; well trimmed ; no plaques ; no plaques ; well trimmed \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=3, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces ; well trimmed ; no plaques ; no plaques \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=4, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEAM Size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: GTEX-13PVR-2726\n",
      "Actual Note: \n",
      " this is a artery - tibial tissue from a female patient and it has 2 pieces, clean specimen, no atherosis\n",
      "Generated Note: \n",
      " this is a artery - tibial tissue from a male patient and it has 2 pieces ; well trimmed ; no plaques ; no plaques ; no plaques \n"
     ]
    }
   ],
   "source": [
    "samp = df[df.pid=='GTEX-13PVR-2726']\n",
    "\n",
    "pid=samp.pid.values[0]\n",
    "print(f'Patient ID: {pid}')\n",
    "print(f'Actual Note: \\n {samp.new_notes.values[0].lower()}')\n",
    "reps256_path=samp['reps_path'].values[0]\n",
    "reps4k_path=samp['reps4kpath'].values[0]\n",
    "\n",
    "x256 = torch.load(reps256_path)\n",
    "x256mean = x256.mean(dim=1)\n",
    "x4k = torch.load(reps4k_path)\n",
    "pixel_values = torch.cat([x256mean, x4k], dim=1).unsqueeze(0)\n",
    "# pixel_values=torch.load(samp.reps_path.values[0]).unsqueeze(0)\n",
    "pixel_values.shape\n",
    "\n",
    "# generate\n",
    "gencap=lightning_model.model.generate(pixel_values, max_length=128, num_beams=5, do_sample=True)\n",
    "\n",
    "decoded_cap=tokenizer.decode(gencap[0])\n",
    "remove_sptokens=decoded_cap[6:decoded_cap.find('[SEP]')]\n",
    "\n",
    "print(f'Generated Note: \\n {remove_sptokens}')\n",
    "# print(f'Full Generated Note: \\n {decoded_cap}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.12.0",
   "language": "python",
   "name": "pytorch-1.12.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
